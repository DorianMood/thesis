{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "cellId": "72u21ycnq0rs1w6zgpynfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'thesis'\n",
      "/home/jupyter/work/resources/thesis\n"
     ]
    }
   ],
   "source": [
    "%cd thesis\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "4ae1hy8wzpw5oxpogsudbw"
   },
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kalj5c8505xmq7ixd29ii"
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.conda.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "cellId": "apbhx4vh1o6eyjvww1l7x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from realesrgan import RealESRGANer\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xmjcse43hceyzor603h0bl"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "u3scr5xripmh8zn6njry4"
   },
   "outputs": [],
   "source": [
    "# Upsampler\n",
    "\n",
    "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64)\n",
    "\n",
    "upsampler = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='./realesrgan/experiments/pretrained_models/RealESRGAN_x4plus.pth',\n",
    "    model=model,\n",
    "    tile=False,\n",
    "    tile_pad=10,\n",
    "    pre_pad=0,\n",
    "    half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hj2nf5daadgolvk8r6q4w"
   },
   "outputs": [],
   "source": [
    "from src.helpers import utils\n",
    "from compress import make_deterministic\n",
    "from src.loss.perceptual_similarity import perceptual_loss as ps\n",
    "from default_config import ModelModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8ly21kyqi6aumumbqcabd"
   },
   "outputs": [],
   "source": [
    "# Compression\n",
    "\n",
    "# Reproducibility\n",
    "make_deterministic()\n",
    "perceptual_loss_fn = ps.PerceptualLoss(model='net-lin', net='alex', use_gpu=torch.cuda.is_available())\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cpu')#utils.get_device()\n",
    "print(device)\n",
    "logger = utils.logger_setup(logpath=os.path.join('images', 'logs'), filepath=os.path.abspath('1'))\n",
    "loaded_args, compression, _ = utils.load_model('experiments/hific_low.pt', logger, device, model_mode=ModelModes.EVALUATION,\n",
    "    current_args_d=None, prediction=True, strict=False)\n",
    "print('logger done')\n",
    "\n",
    "#compression.Hyperprior.hyperprior_entropy_model.build_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ewy3kz4g3r86gq0p8ki2g7"
   },
   "outputs": [],
   "source": [
    "# Input size: [2, 220, 8, 8]\n",
    "\n",
    "input = torch.rand(1, 220, 8, 8)\n",
    "\n",
    "result = compression.Generator(input)\n",
    "summary(compression.Generator, (220, 8, 8), 1, device='cpu')\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ffysk6c6fvj6j9qsem5vaf"
   },
   "outputs": [],
   "source": [
    "summary(compression.Encoder, (3, 128, 128), 2, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "d1si6aax037tnae745b2ep"
   },
   "outputs": [],
   "source": [
    "result = compression.Hyperprior(torch.rand((2, 220, 8, 8)), (128, 128))\n",
    "\n",
    "print(result.decoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5phyz8ol42d7pefmz6v4hx"
   },
   "outputs": [],
   "source": [
    "summary(upsampler.model, (3, 128, 128), 1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "m9bgt5wch2oyft3e602zk"
   },
   "outputs": [],
   "source": [
    "compression.train(False)\n",
    "compression(torch.rand((16, 3, 128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7132kdlr1uf5z4g9si76"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, compression, upsampler):\n",
    "        super().__init__()\n",
    "        self.compression = compression\n",
    "        self.upsampler = upsampler\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y, loss = self.compression(x)\n",
    "        y = self.upsampler(y)\n",
    "        return y\n",
    "\n",
    "    def train(self, train=True):\n",
    "        self.compression.train(False)\n",
    "        self.compression.Generator.train(train)\n",
    "        self.upsampler.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nz4zgmhb48lnwe2mw5s5s"
   },
   "outputs": [],
   "source": [
    "m = Model(compression, upsampler.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dma147xhzi7tccex7hxll"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 128, 128)\n",
    "result = m(x)\n",
    "\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s3kmxsp0udqz0d5hyocceg"
   },
   "source": [
    "## Generator network\n",
    "\n",
    "### Remarks\n",
    "- Conv2D with 2x2 padding that's equivalent to Conv2DTranspose with no padding.\n",
    "- Checkerboard artifacts can start to become an issue when using strides (even after stacking multiple layers).\n",
    "\n",
    "### Things to try: \n",
    "\n",
    "1. To avoid checkerboard artifacts, an alternative upsampling method thatâ€™s gaining popularity is to apply classical upsampling followed by a regular convolution (that preserves the spatial dimensions).\n",
    "\n",
    "### A classical structure used in such networks as pix2pixHD and almost every other project\n",
    "\n",
    "1. Convolutional network for extracting features\n",
    "2. Residual network\n",
    "3. Deconvolution is build up with ConvTranspose2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "sprq2x1jdfdj5d5t9h7s"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.normalisation import channel, instance\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, input_dims, kernel_size=3, stride=1, \n",
    "                 channel_norm=True, activation='relu'):\n",
    "        \"\"\"\n",
    "        input_dims: Dimension of input tensor (B,C,H,W)\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.activation = getattr(F, activation)\n",
    "        in_channels = input_dims[1]\n",
    "        norm_kwargs = dict(momentum=0.1, affine=True, track_running_stats=False)\n",
    "\n",
    "        if channel_norm is True:\n",
    "            self.interlayer_norm = channel.ChannelNorm2D_wrap\n",
    "        else:\n",
    "            self.interlayer_norm = instance.InstanceNorm2D_wrap\n",
    "\n",
    "        pad_size = int((kernel_size-1)/2)\n",
    "        self.pad = torch.nn.ReflectionPad2d(pad_size)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride)\n",
    "        self.norm1 = self.interlayer_norm(in_channels, **norm_kwargs)\n",
    "        self.norm2 = self.interlayer_norm(in_channels, **norm_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity_map = x\n",
    "        res = self.pad(x)\n",
    "        res = self.conv1(res)\n",
    "        res = self.norm1(res) \n",
    "        res = self.activation(res)\n",
    "\n",
    "        res = self.pad(res)\n",
    "        res = self.conv2(res)\n",
    "        res = self.norm2(res)\n",
    "\n",
    "        return torch.add(res, identity_map)\n",
    "\n",
    "class Upsampler(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dims, batch_size, C=220, activation='relu',\n",
    "                 n_residual_blocks=8, channel_norm=True, sample_noise=False,\n",
    "                 noise_dim=32, silent=True):\n",
    "        super(Upsampler, self).__init__()\n",
    "        self.silent = silent\n",
    "\n",
    "        kernel_dim = 3\n",
    "        filters = [960, 480, 240, 120, 60]\n",
    "        self.n_residual_blocks = n_residual_blocks\n",
    "        self.sample_noise = sample_noise\n",
    "        self.noise_dim = noise_dim\n",
    "\n",
    "        # Layer / normalization options\n",
    "        cnn_kwargs = dict(stride=2, padding=1, output_padding=1)\n",
    "        norm_kwargs = dict(momentum=0.1, affine=True, track_running_stats=False)\n",
    "        activation_d = dict(relu='ReLU', elu='ELU', leaky_relu='LeakyReLU')\n",
    "        self.activation = getattr(torch.nn, activation_d[activation])  # (leaky_relu, relu, elu)\n",
    "        self.n_upsampling_layers = 4\n",
    "        \n",
    "        if channel_norm is True:\n",
    "            self.interlayer_norm = channel.ChannelNorm2D_wrap\n",
    "        else:\n",
    "            self.interlayer_norm = instance.InstanceNorm2D_wrap\n",
    "\n",
    "        self.pre_pad = torch.nn.ReflectionPad2d(1)\n",
    "        self.asymmetric_pad = torch.nn.ReflectionPad2d((0,1,1,0))  # Slower than tensorflow?\n",
    "        self.post_pad = torch.nn.ReflectionPad2d(3)\n",
    "\n",
    "        H0, W0 = input_dims[1:]\n",
    "        heights = [2**i for i in range(5,9)]\n",
    "        widths = heights\n",
    "        H1, H2, H3, H4 = heights\n",
    "        W1, W2, W3, W4 = widths \n",
    "\n",
    "\n",
    "        # (16,16) -> (16,16), with implicit padding\n",
    "        self.conv_block_init = torch.nn.Sequential(\n",
    "            self.interlayer_norm(C, **norm_kwargs),\n",
    "            self.pre_pad,\n",
    "            torch.nn.Conv2d(C, filters[0], kernel_size=(3,3), stride=1),\n",
    "            self.interlayer_norm(filters[0], **norm_kwargs),\n",
    "        )\n",
    "\n",
    "        if sample_noise is True:\n",
    "            # Concat noise with latent representation\n",
    "            filters[0] += self.noise_dim\n",
    "\n",
    "        for m in range(n_residual_blocks):\n",
    "            resblock_m = ResidualBlock(input_dims=(batch_size, filters[0], H0, W0), \n",
    "                channel_norm=channel_norm, activation=activation)\n",
    "            self.add_module(f'resblock_{str(m)}', resblock_m)\n",
    "        \n",
    "        self.upconv_block1 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(filters[0], filters[1], kernel_dim, **cnn_kwargs),\n",
    "            self.interlayer_norm(filters[1], **norm_kwargs),\n",
    "            self.activation(),\n",
    "        )\n",
    "        self.upconv_block2 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(filters[1], filters[2], kernel_dim, **cnn_kwargs),\n",
    "            self.interlayer_norm(filters[2], **norm_kwargs),\n",
    "            self.activation(),\n",
    "        )\n",
    "        self.upconv_block3 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(filters[2], filters[3], kernel_dim, **cnn_kwargs),\n",
    "            self.interlayer_norm(filters[3], **norm_kwargs),\n",
    "            self.activation(),\n",
    "        )\n",
    "        self.upconv_block4 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(filters[3], filters[4], kernel_dim, **cnn_kwargs),\n",
    "            self.interlayer_norm(filters[4], **norm_kwargs),\n",
    "            self.activation(),\n",
    "        )\n",
    "        self.conv_block_out = torch.nn.Sequential(\n",
    "            self.post_pad,\n",
    "            torch.nn.Conv2d(filters[-1], 3, kernel_size=(7,7), stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        head = self.conv_block_init(x)\n",
    "\n",
    "        if self.sample_noise is True:\n",
    "            B, C, H, W = tuple(head.size())\n",
    "            z = torch.randn((B, self.noise_dim, H, W)).to(head)\n",
    "            head = torch.cat((head,z), dim=1)\n",
    "\n",
    "        for m in range(self.n_residual_blocks):\n",
    "            resblock_m = getattr(self, f'resblock_{str(m)}')\n",
    "            if m == 0:\n",
    "                x = resblock_m(head)\n",
    "            else:\n",
    "                x = resblock_m(x)\n",
    "        \n",
    "        x += head\n",
    "        x = self.upconv_block1(x)\n",
    "        x = self.upconv_block2(x)\n",
    "        x = self.upconv_block3(x)\n",
    "        #x = torch.nn.functional.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.upconv_block4(x)\n",
    "        out = self.conv_block_out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9yih91my659rdlq7kefbp"
   },
   "outputs": [],
   "source": [
    "upsampler = Upsampler([220, 8, 8], 2, n_residual_blocks=7)\n",
    "\n",
    "input = torch.rand(2, 220, 8, 8)\n",
    "output = upsampler(input)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "agqfxvtu8wlix505bdqsu"
   },
   "outputs": [],
   "source": [
    "upsampler.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vyh1bebmc4knt58nxy32o"
   },
   "source": [
    "#### Try using interpolation to upscale feature maps. Need to match shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hm55cs15t3u0y9k9p5ylr0l"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "shape = (2, 220, 8, 8)\n",
    "\n",
    "input = torch.rand(shape)\n",
    "output1 = F.interpolate(input, scale_factor=2, mode='nearest')\n",
    "\n",
    "print(input.shape, output1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "18gtihy5csuvnk508nzgc"
   },
   "source": [
    "### Load model from checkpoint and modify structure of Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0f9a33p72gzalau5llpi9uc"
   },
   "outputs": [],
   "source": [
    "# Compression\n",
    "import torch\n",
    "from src.helpers import utils\n",
    "from compress import make_deterministic\n",
    "from src.loss.perceptual_similarity import perceptual_loss as ps\n",
    "from default_config import ModelModes\n",
    "\n",
    "# Reproducibility\n",
    "make_deterministic()\n",
    "perceptual_loss_fn = ps.PerceptualLoss(model='net-lin', net='alex', use_gpu=torch.cuda.is_available())\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cpu')#utils.get_device()\n",
    "logger = utils.logger_setup(logpath=os.path.join('images', 'logs'), filepath=os.path.abspath('1'))\n",
    "loaded_args, compression, _ = utils.load_model('experiments/hific_low.pt', logger, device, model_mode=ModelModes.EVALUATION,\n",
    "    current_args_d=None, prediction=True, strict=False, silent=True)\n",
    "\n",
    "#compression.Hyperprior.hyperprior_entropy_model.build_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4hea0z4e7ca4tlwi2c46au"
   },
   "outputs": [],
   "source": [
    "upsampler = Upsampler((220, 8, 8), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "s83bn4o88ftzp9rqhjz6es"
   },
   "outputs": [],
   "source": [
    "compression.train(False)\n",
    "compression.Generator = upsampler\n",
    "compression.Generator.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "a7u065odom8u7ihiz9g78j"
   },
   "outputs": [],
   "source": [
    "input = torch.rand((1, 3, 128, 128))\n",
    "output = compression(input)\n",
    "\n",
    "print(f'OUTPUT SHAPE : {output[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9k0eq02xiii6bek7adesj"
   },
   "source": [
    "### Now we got to train the network\n",
    "\n",
    "For this purpose we need:\n",
    "\n",
    "1. Set up a dataset\n",
    "2. Run training script from hific repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "l6aj195tw4fmmi82ay0jk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (1.12.31)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.6.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /home/jupyter/.local/lib/python3.8/site-packages (from boto3) (1.15.49)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/jupyter/.local/lib/python3.8/site-packages (from boto3) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /kernel/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.5.2)\n",
      "Collecting ipython>=4.0.0\n",
      "  Downloading ipython-7.13.0-py3-none-any.whl (780 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780 kB 1.3 MB/s            \n",
      "\u001b[?25hCollecting ipykernel>=4.5.1\n",
      "  Downloading ipykernel-5.1.4-py3-none-any.whl (116 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116 kB 13.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils~=0.2.0 in /kernel/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /kernel/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/jupyter/.local/lib/python3.8/site-packages (from botocore<1.16.0,>=1.15.31->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /home/jupyter/.local/lib/python3.8/site-packages (from botocore<1.16.0,>=1.15.31->boto3) (1.25.10)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.8/dist-packages (from botocore<1.16.0,>=1.15.31->boto3) (0.15.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /kernel/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /kernel/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.26)\n",
      "Requirement already satisfied: pygments in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (51.0.0)\n",
      "Requirement already satisfied: pexpect in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/jupyter/.local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /kernel/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jupyter-core in /kernel/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /kernel/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Downloading notebook-6.1.1-py3-none-any.whl (9.4 MB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.4 MB 22.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: parso<0.8.0,>=0.7.0 in /kernel/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /kernel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /kernel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /kernel/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: Send2Trash in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: nbconvert in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: prometheus-client in /kernel/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /kernel/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyter/.local/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.31->boto3) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /kernel/lib/python3.8/site-packages (from pexpect->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/jupyter/.local/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.1.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /kernel/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: defusedxml in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /kernel/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.10)\n",
      "Requirement already satisfied: nest-asyncio in /kernel/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /kernel/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: packaging in /kernel/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: webencodings in /kernel/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /kernel/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: ipython, ipykernel, notebook\n",
      "\u001b[33m  WARNING: The scripts iptest, iptest3, ipython and ipython3 are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts jupyter-bundlerextension, jupyter-nbextension, jupyter-notebook and jupyter-serverextension are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed ipykernel-5.1.4 ipython-7.13.0 notebook-6.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "npjtttomckzmkxpanfzyi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "It's init dataset task. State result won't be merged.\n"
      ]
     },
     "metadata": {
      "info_type": "execution_status"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f3c2822d214187a5f77f0614d172d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49310925536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/home/jupyter/mnt/datasets/OPEN_IMAGES/train_data/train_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3847fe53243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtrain_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{train_dir}/{SUBSET_NAME}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{train_dir}/../train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0o700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m             \u001b[0;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2028\u001b[0;31m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2029\u001b[0m                          numeric_owner=numeric_owner)\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2070\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m                                  numeric_owner=numeric_owner)\n",
      "\u001b[0;32m/usr/lib/python3.8/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0;31m# Create directories that are not part of the archive with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# default permissions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupperdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislnk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missym\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/home/jupyter/mnt/datasets/OPEN_IMAGES/train_data/train_0'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:872: UserWarning: The following variables cannot be serialized: pbar, s3, tar\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unpacking...\n",
      "Unmounting dataset OPEN_IMAGES... ok\n"
     ]
    }
   ],
   "source": [
    "#pragma dataset init OPEN_IMAGES --size 128Gb\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Download dataset\n",
    "\n",
    "DATASET_PATH = '/home/jupyter/mnt/datasets/OPEN_IMAGES'\n",
    "HOME_PATH = '/home/jupyter/work/resources/thesis'\n",
    "\n",
    "SUBSET_NAME = 'train_0'\n",
    "\n",
    "BUCKET = 'open-images-dataset'\n",
    "KEY = f'tar/{SUBSET_NAME}.tar.gz'\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "metadata = s3.head_object(Bucket=BUCKET, Key=KEY)\n",
    "\n",
    "with tqdm(total=metadata['ContentLength'], unit=\"B\", unit_scale=True) as pbar:\n",
    "    s3.download_file(BUCKET, KEY, f'{DATASET_PATH}/{SUBSET_NAME}.tar.gz', Callback=lambda bytes_transfered: pbar.update(bytes_transfered))\n",
    "\n",
    "# Unpack dataset\n",
    "    \n",
    "print('Unpacking...')\n",
    "\n",
    "train_dir = os.path.abspath(f'{DATASET_PATH}/train_data')\n",
    "valid_dir = os.path.abspath(f'{DATASET_PATH}/valid_data')\n",
    "\n",
    "try:\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(valid_dir)\n",
    "except:\n",
    "    print('Directories already created.')\n",
    "\n",
    "with tarfile.open(os.path.abspath(f'{DATASET_PATH}/{SUBSET_NAME}.tar.gz'), 'r:gz') as tar:\n",
    "    file_names = tar.getmembers()\n",
    "    length = len(file_names)\n",
    "    train_ratio = 0.8\n",
    "    train, valid = slice(0, math.ceil(length * train_ratio)), slice(math.ceil(length * train_ratio), -1)\n",
    "    tar.extractall(train_dir, file_names[train])\n",
    "    os.rename(f'{train_dir}/{SUBSET_NAME}', f'{train_dir}/../train')\n",
    "    tar.extractall(valid_dir, file_names[valid])\n",
    "    os.rename(f'{valid_dir}/{SUBSET_NAME}', f'{valid_dir}/../valid')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "ff0clvmhcjicpfy0lb6gzm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, time, datetime\n",
    "import pickle, argparse\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import defaultdict\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Custom modules\n",
    "from src.model import Model\n",
    "from src.helpers import utils, datasets\n",
    "from default_config import hific_args, mse_lpips_args, directories, ModelModes, ModelTypes\n",
    "\n",
    "# go fast boi!!\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def create_model(args, device, logger, storage, storage_test):\n",
    "\n",
    "    start_time = time.time()\n",
    "    model = Model(args, logger, storage, storage_test, model_type=args.model_type)\n",
    "    logger.info(model)\n",
    "    logger.info('Trainable parameters:')\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "        logger.info('{} - {}'.format(n, p.shape))\n",
    "\n",
    "    logger.info(\"Number of trainable parameters: {}\".format(utils.count_parameters(model)))\n",
    "    logger.info(\"Estimated size (under fp32): {:.3f} MB\".format(utils.count_parameters(model) * 4. / 10**6))\n",
    "    logger.info('Model init {:.3f}s'.format(time.time() - start_time))\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_loss(loss, opt, retain_graph=False):\n",
    "    loss.backward(retain_graph=retain_graph)\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "def optimize_compression_loss(compression_loss, amortization_opt, hyperlatent_likelihood_opt):\n",
    "    compression_loss.backward()\n",
    "    amortization_opt.step()\n",
    "    hyperlatent_likelihood_opt.step()\n",
    "    amortization_opt.zero_grad()\n",
    "    hyperlatent_likelihood_opt.zero_grad()\n",
    "\n",
    "def test(args, model, epoch, idx, data, test_data, test_bpp, device, epoch_test_loss, storage, best_test_loss, \n",
    "         start_time, epoch_start_time, logger, train_writer, test_writer):\n",
    "\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "\n",
    "        losses, intermediates = model(data, return_intermediates=True, writeout=False)\n",
    "        utils.save_images(train_writer, model.step_counter, intermediates.input_image, intermediates.reconstruction,\n",
    "            fname=os.path.join(args.figures_save, 'recon_epoch{}_idx{}_TRAIN_{:%Y_%m_%d_%H:%M}.jpg'.format(epoch, idx, datetime.datetime.now())))\n",
    "\n",
    "        test_data = test_data.to(device, dtype=torch.float)\n",
    "        losses, intermediates = model(test_data, return_intermediates=True, writeout=True)\n",
    "        utils.save_images(test_writer, model.step_counter, intermediates.input_image, intermediates.reconstruction,\n",
    "            fname=os.path.join(args.figures_save, 'recon_epoch{}_idx{}_TEST_{:%Y_%m_%d_%H:%M}.jpg'.format(epoch, idx, datetime.datetime.now())))\n",
    "    \n",
    "        compression_loss = losses['compression'] \n",
    "        epoch_test_loss.append(compression_loss.item())\n",
    "        mean_test_loss = np.mean(epoch_test_loss)\n",
    "        \n",
    "        best_test_loss = utils.log(model, storage, epoch, idx, mean_test_loss, compression_loss.item(), \n",
    "                                     best_test_loss, start_time, epoch_start_time, \n",
    "                                     batch_size=data.shape[0], avg_bpp=test_bpp.mean().item(),header='[TEST]', \n",
    "                                     logger=logger, writer=test_writer)\n",
    "    \n",
    "    return best_test_loss, epoch_test_loss\n",
    "\n",
    "\n",
    "def train(args, model, train_loader, test_loader, device, logger, optimizers):\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_loader_iter = iter(test_loader)\n",
    "    current_D_steps, train_generator = 0, True\n",
    "    best_loss, best_test_loss, mean_epoch_loss = np.inf, np.inf, np.inf     \n",
    "    train_writer = SummaryWriter(os.path.join(args.tensorboard_runs, 'train'))\n",
    "    test_writer = SummaryWriter(os.path.join(args.tensorboard_runs, 'test'))\n",
    "    storage, storage_test = model.storage_train, model.storage_test\n",
    "\n",
    "    amortization_opt, hyperlatent_likelihood_opt = optimizers['amort'], optimizers['hyper']\n",
    "    if model.use_discriminator is True:\n",
    "        disc_opt = optimizers['disc']\n",
    "\n",
    "    for epoch in trange(args.n_epochs, desc='Epoch'):\n",
    "\n",
    "        epoch_loss, epoch_test_loss = [], []  \n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        if epoch > 0:\n",
    "            ckpt_path = utils.save_model(model, optimizers, mean_epoch_loss, epoch, device, args=args, logger=logger)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for idx, (data, bpp) in enumerate(tqdm(train_loader, desc='Train', position=0, leave=True), 0):\n",
    "\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            \n",
    "            try:\n",
    "                if model.use_discriminator is True:\n",
    "                    # Train D for D_steps, then G, using distinct batches\n",
    "                    losses = model(data, train_generator=train_generator)\n",
    "                    compression_loss = losses['compression']\n",
    "                    disc_loss = losses['disc']\n",
    "\n",
    "                    if train_generator is True:\n",
    "                        optimize_compression_loss(compression_loss, amortization_opt, hyperlatent_likelihood_opt)\n",
    "                        train_generator = False\n",
    "                    else:\n",
    "                        optimize_loss(disc_loss, disc_opt)\n",
    "                        current_D_steps += 1\n",
    "\n",
    "                        if current_D_steps == args.discriminator_steps:\n",
    "                            current_D_steps = 0\n",
    "                            train_generator = True\n",
    "\n",
    "                        continue\n",
    "                else:\n",
    "                    # Rate, distortion, perceptual only\n",
    "                    losses = model(data, train_generator=True)\n",
    "                    compression_loss = losses['compression']\n",
    "                    optimize_compression_loss(compression_loss, amortization_opt, hyperlatent_likelihood_opt)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                # Note: saving not guaranteed!\n",
    "                if model.step_counter > args.log_interval+1:\n",
    "                    logger.warning('Exiting, saving ...')\n",
    "                    ckpt_path = utils.save_model(model, optimizers, mean_epoch_loss, epoch, device, args=args, logger=logger)\n",
    "                    return model, ckpt_path\n",
    "                else:\n",
    "                    return model, None\n",
    "\n",
    "            if model.step_counter % args.log_interval == 1:\n",
    "                epoch_loss.append(compression_loss.item())\n",
    "                mean_epoch_loss = np.mean(epoch_loss)\n",
    "\n",
    "                best_loss = utils.log(model, storage, epoch, idx, mean_epoch_loss, compression_loss.item(),\n",
    "                                best_loss, start_time, epoch_start_time, batch_size=data.shape[0],\n",
    "                                avg_bpp=bpp.mean().item(), logger=logger, writer=train_writer)\n",
    "                try:\n",
    "                    test_data, test_bpp = test_loader_iter.next()\n",
    "                except StopIteration:\n",
    "                    test_loader_iter = iter(test_loader)\n",
    "                    test_data, test_bpp = test_loader_iter.next()\n",
    "\n",
    "                best_test_loss, epoch_test_loss = test(args, model, epoch, idx, data, test_data, test_bpp, device, epoch_test_loss, storage_test,\n",
    "                     best_test_loss, start_time, epoch_start_time, logger, train_writer, test_writer)\n",
    "\n",
    "                with open(os.path.join(args.storage_save, 'storage_{}_tmp.pkl'.format(args.name)), 'wb') as handle:\n",
    "                    pickle.dump(storage, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                # LR scheduling\n",
    "                utils.update_lr(args, amortization_opt, model.step_counter, logger)\n",
    "                utils.update_lr(args, hyperlatent_likelihood_opt, model.step_counter, logger)\n",
    "                if model.use_discriminator is True:\n",
    "                    utils.update_lr(args, disc_opt, model.step_counter, logger)\n",
    "\n",
    "                if model.step_counter > args.n_steps:\n",
    "                    logger.info('Reached step limit [args.n_steps = {}]'.format(args.n_steps))\n",
    "                    break\n",
    "\n",
    "            if (idx % args.save_interval == 1) and (idx > args.save_interval):\n",
    "                ckpt_path = utils.save_model(model, optimizers, mean_epoch_loss, epoch, device, args=args, logger=logger)\n",
    "\n",
    "        # End epoch\n",
    "        mean_epoch_loss = np.mean(epoch_loss)\n",
    "        mean_epoch_test_loss = np.mean(epoch_test_loss)\n",
    "\n",
    "        logger.info('===>> Epoch {} | Mean train loss: {:.3f} | Mean test loss: {:.3f}'.format(epoch, \n",
    "            mean_epoch_loss, mean_epoch_test_loss))    \n",
    "\n",
    "        if model.step_counter > args.n_steps:\n",
    "            break\n",
    "    \n",
    "    with open(os.path.join(args.storage_save, 'storage_{}_{:%Y_%m_%d_%H:%M:%S}.pkl'.format(args.name, datetime.datetime.now())), 'wb') as handle:\n",
    "        pickle.dump(storage, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    ckpt_path = utils.save_model(model, optimizers, mean_epoch_loss, epoch, device, args=args, logger=logger)\n",
    "    args.ckpt = ckpt_path\n",
    "    logger.info(\"Training complete. Time elapsed: {:.3f} s. Number of steps: {}\".format((time.time()-start_time), model.step_counter))\n",
    "    \n",
    "    return model, ckpt_path\n",
    "\n",
    "\n",
    "def run(generator: torch.nn.Module = None):\n",
    "    cmd_args = AttrDict({\n",
    "        \"model_type\": ModelTypes.COMPRESSION,\n",
    "        \"normalize_input_image\": False,\n",
    "        \"save\": \"experiments\",\n",
    "        \"use_latent_mixture_model\": False,\n",
    "        \"warmstart\": False,\n",
    "        \"warmstart_ckpt\": None,\n",
    "        \"multigpu\": False,\n",
    "        \"gpu\": 0,\n",
    "        \"force_set_gpu\": True\n",
    "    })\n",
    "\n",
    "    if (cmd_args.gpu != 0) or (cmd_args.force_set_gpu is True):\n",
    "        torch.cuda.set_device(cmd_args.gpu)\n",
    "\n",
    "    if cmd_args.model_type == ModelTypes.COMPRESSION:\n",
    "        args = mse_lpips_args\n",
    "    elif cmd_args.model_type == ModelTypes.COMPRESSION_GAN:\n",
    "        args = hific_args\n",
    "\n",
    "    start_time = time.time()\n",
    "    device = utils.get_device()\n",
    "\n",
    "    # Override default arguments from config file with provided command line arguments\n",
    "    dictify = lambda x: dict((n, getattr(x, n)) for n in dir(x) if not (n.startswith('__') or 'logger' in n))\n",
    "    args_d, cmd_args_d = dictify(args), vars(cmd_args)\n",
    "    args_d.update(cmd_args_d)\n",
    "    args = utils.Struct(**args_d)\n",
    "    args = utils.setup_generic_signature(args, special_info=args.model_type)\n",
    "    args.target_rate = args.target_rate_map[args.regime]\n",
    "    args.lambda_A = args.lambda_A_map[args.regime]\n",
    "    args.n_steps = int(args.n_steps)\n",
    "    args.warmstart = cmd_args.warmstart\n",
    "\n",
    "    storage = defaultdict(list)\n",
    "    storage_test = defaultdict(list)\n",
    "    logger = utils.logger_setup(logpath=os.path.join(args.snapshot, 'logs'), filepath=os.getcwd())\n",
    "\n",
    "    if args.warmstart is True:\n",
    "        assert args.warmstart_ckpt is not None, 'Must provide checkpoint to previously trained AE/HP model.'\n",
    "        logger.info('Warmstarting discriminator/generator from autoencoder/hyperprior model.')\n",
    "        if args.model_type != ModelTypes.COMPRESSION_GAN:\n",
    "            logger.warning('Should warmstart compression-gan model.')\n",
    "        # TODO : Define a custom model type and pass it through these frunctions\n",
    "        args, model, optimizers = utils.load_model(args.warmstart_ckpt, logger, device, \n",
    "            model_type=args.model_type, current_args_d=dictify(args), strict=False, prediction=False)\n",
    "    else:\n",
    "        model = create_model(args, device, logger, storage, storage_test)\n",
    "\n",
    "        # In case we are starting training, attach custom generator here\n",
    "        if generator:\n",
    "            model.Generator = generator\n",
    "\n",
    "        model = model.to(device)\n",
    "        amortization_parameters = itertools.chain.from_iterable(\n",
    "            [am.parameters() for am in model.amortization_models])\n",
    "\n",
    "        hyperlatent_likelihood_parameters = model.Hyperprior.hyperlatent_likelihood.parameters()\n",
    "\n",
    "        amortization_opt = torch.optim.Adam(amortization_parameters,\n",
    "            lr=args.learning_rate)\n",
    "        hyperlatent_likelihood_opt = torch.optim.Adam(hyperlatent_likelihood_parameters, \n",
    "            lr=args.learning_rate)\n",
    "        optimizers = dict(amort=amortization_opt, hyper=hyperlatent_likelihood_opt)\n",
    "\n",
    "        if model.use_discriminator is True:\n",
    "            discriminator_parameters = model.Discriminator.parameters()\n",
    "            disc_opt = torch.optim.Adam(discriminator_parameters, lr=args.learning_rate)\n",
    "            optimizers['disc'] = disc_opt\n",
    "\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    if n_gpus > 1 and args.multigpu is True:\n",
    "        # Not supported at this time\n",
    "        raise NotImplementedError('MultiGPU not supported yet.')\n",
    "        logger.info('Using {} GPUs.'.format(n_gpus))\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    logger.info('MODEL TYPE: {}'.format(args.model_type))\n",
    "    logger.info('MODEL MODE: {}'.format(args.model_mode))\n",
    "    logger.info('BITRATE REGIME: {}'.format(args.regime))\n",
    "    logger.info('SAVING LOGS/CHECKPOINTS/RECORDS TO {}'.format(args.snapshot))\n",
    "    logger.info('USING DEVICE {}'.format(device))\n",
    "    logger.info('USING GPU ID {}'.format(args.gpu))\n",
    "    logger.info('USING DATASET: {}'.format(args.dataset))\n",
    "\n",
    "    test_loader = datasets.get_dataloaders(args.dataset,\n",
    "                                root=args.dataset_path,\n",
    "                                batch_size=args.batch_size,\n",
    "                                logger=logger,\n",
    "                                mode='validation',\n",
    "                                shuffle=True,\n",
    "                                normalize=args.normalize_input_image)\n",
    "\n",
    "    train_loader = datasets.get_dataloaders(args.dataset,\n",
    "                                root=args.dataset_path,\n",
    "                                batch_size=args.batch_size,\n",
    "                                logger=logger,\n",
    "                                mode='train',\n",
    "                                shuffle=True,\n",
    "                                normalize=args.normalize_input_image)\n",
    "\n",
    "    args.n_data = len(train_loader.dataset)\n",
    "    args.image_dims = train_loader.dataset.image_dims\n",
    "    logger.info('Training elements: {}'.format(args.n_data))\n",
    "    logger.info('Input Dimensions: {}'.format(args.image_dims))\n",
    "    logger.info('Optimizers: {}'.format(optimizers))\n",
    "    logger.info('Using device {}'.format(device))\n",
    "\n",
    "    metadata = dict((n, getattr(args, n)) for n in dir(args) if not (n.startswith('__') or 'logger' in n))\n",
    "    logger.info(metadata)\n",
    "\n",
    "    \"\"\"\n",
    "    Train\n",
    "    \"\"\"\n",
    "    model, ckpt_path = train(args, model, train_loader, test_loader, device, logger, optimizers=optimizers)\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO\n",
    "    Generate metrics\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rqvi9uxxoz9pz41b6xlv6q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1ipuo30ezmqbqrmusn4d5u"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /home/jupyter/work/resources/thesis/experiments/hific_v0.1_openimages_compression_2022_02_09_10_26"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35cdeedb3a6aa6a2b0bc182c198fb1618a1bb197b1dc798243fe66edd9d09358"
  },
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "3e86c763-724a-45eb-884d-3dec02c91853",
  "notebookPath": "thesis/Model.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
